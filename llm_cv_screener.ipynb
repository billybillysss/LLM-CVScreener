{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter  import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"./cv\"\n",
    "persist_directory= \"./vectorstore/db\"\n",
    "n_doc = 3 ##number of documents return\n",
    "\n",
    "loader = DirectoryLoader(path = path, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "embeddings = OllamaEmbeddings(base_url=os.getenv(\"OLLAMA_ADDR\"), model=os.getenv(\"OLLAMA_MODEL\"))\n",
    "\n",
    "llm = Ollama(base_url=os.getenv(\"OLLAMA_ADDR\"), model=os.getenv(\"OLLAMA_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter  = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
    "text_splitter.split_documents(documents)\n",
    "vectorstore = Chroma.from_documents(persist_directory=persist_directory, embedding=embeddings, documents=documents)\n",
    "retriver = vectorstore.as_retriever(search_type=\"mmr\",search_kwargs= {\"k\": n_doc} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(path):\n",
    "    with open(path, mode=\"r+\", encoding= \"utf-8\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "responsibilities:\n",
      "• Design, develop, and maintain multiple databases within the data warehouse. \n",
      "• Create, implement, and test data models and database management systems.\n",
      "• Conduct research and support internal/external groups with the selection and implementation of applications and database management tools.\n",
      "• Identify and utilize database management systems to aggregate and analyze data. \n",
      "• In collaboration with the VP, IBT and the Senior Data Warehouse Engineer, develop and implement data administration policies, standards, and models. \n",
      "• Work with internal departments and colleagues to understand and document specific data and user requirements, data collection and administration policies, and data access rules. \n",
      "• Develop and implement procedures for determining network access and usage and for the backup and recovery of data. \n",
      "• Write scripts to support automation, data extraction, and reporting.\n",
      "• Design and automate routine and self-service reporting solutions (i.e., Power BI).\n",
      "• Identify opportunities and provide recommendations to enhance efficiencies in data management and analysis. \n",
      "• Create and maintain system context diagrams and process maps, capturing flows of information between systems and typical customer flows.\n",
      "• Analyze business operations and workflows to understand and define opportunities where information solutions can be implemented to mitigate business challenges.\n",
      "• Perform ad-hoc data extraction, analysis, and interpretation.\n"
     ]
    }
   ],
   "source": [
    "jd_path = \"jd\\job_description.txt\"\n",
    "jd=file_reader(jd_path)\n",
    "print(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_result = retriver.invoke(F\"\"\"find the CV with the best match with the JD as below:\n",
    "   {jd}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Name: Emily Smith\\n\\nEmail: emily.smith@example.com\\n\\nPhone: +1-555-901-2345\\n\\nLocation: Vancouver, BC\\n\\nProfessional Summary\\n\\nAnalytical and detail-oriented data analyst with 2 years of experience in data cleaning, analysis, and visualization. Strong background in economics and statistics.\\n\\nSkills\\n\\nPython, R\\n\\nData Visualization (Tableau, Power BI)\\n\\nSQL\\n\\nExcel\\n\\nStatistical Analysis\\n\\nWork Experience\\n\\nData Analyst\\n\\nMarket Research Inc., Vancouver, BC\\n\\nMarch 2022 - Present\\n\\nConducted data analysis to support market research projects.\\n\\nCreated visualizations to communicate findings to clients.\\n\\nResearch Assistant\\n\\nUniversity of British Columbia, Vancouver, BC\\n\\nJanuary 2020 - February 2022\\n\\nAssisted in economic research and data analysis.\\n\\nEducation\\n\\nBachelor of Arts in Economics\\n\\nUniversity of British Columbia, Vancouver, BC\\n\\n2015 - 2019\\n\\nCertifications\\n\\nCertified Business Intelligence Professional (CBIP)', metadata={'source': 'CV\\\\Emily_Smith_CV.md'}),\n",
       " Document(page_content='Name: Michael Chen\\n\\nEmail: michael.chen@example.com\\n\\nPhone: +1-555-567-8901\\n\\nLocation: Ottawa, ON\\n\\nProfessional Summary\\n\\nProficient data engineer with extensive experience in data modeling, ETL development,\\n\\nand big data technologies. Skilled in designing data architectures that support\\n\\nadvanced analytics and machine learning projects.\\n\\nSkills\\n\\nSQL, NoSQL\\n\\nData Modeling\\n\\nETL Processes (Apache Airflow, Talend)\\n\\nBig Data (Hadoop, Spark)\\n\\nCloud Platforms (Azure, AWS) • Python, Java • Data Lake Design\\n\\nWork Experience\\n\\nData Engineer\\n\\nBig Data Solutions, Ottawa, ON\\n\\nSeptember 2017 - Present\\n\\nDeveloped and maintained data lakes on AWS S3.\\n\\nCreated data models and ETL pipelines for large-scale data processing.\\n\\n\\n\\nImplemented data governance and quality assurance processes.\\n\\nJunior Data Engineer\\n\\nTech Data Corp., Ottawa, ON\\n\\nJune 2015 - August 2017\\n\\nAssisted in the design and implementation of data integration solutions.\\n\\nMonitored and optimized data pipeline performance.\\n\\nCollaborated with data analysts to provide data for reporting and analysis.\\n\\nEducation\\n\\nBachelor of Science in Software Engineering\\n\\nCarleton University, Ottawa, ON\\n\\n2011 - 2015\\n\\nCertifications\\n\\nMicrosoft Certified: Azure Data Engineer Associate', metadata={'source': 'CV\\\\Michael_Chen_CV.pdf'}),\n",
       " Document(page_content='Name: Michael Chen\\nEmail: michael.chen@example.com\\nPhone: +1-555-567-8901\\nLocation: Ottawa, ON\\nProfessional Summary\\n\\nProficient data engineer with extensive experience in data modeling, ETL development, and big data technologies. Skilled in designing data architectures that support advanced analytics and machine learning projects.\\nSkills\\n\\nWork Experience\\n\\nData Engineer\\nBig Data Solutions, Ottawa, ON\\nSeptember 2017 - Present\\n\\nJunior Data Engineer\\nTech Data Corp., Ottawa, ON\\nJune 2015 - August 2017\\n\\nEducation\\n\\nBachelor of Science in Software Engineering\\nCarleton University, Ottawa, ON\\n2011 - 2015\\nCertifications', metadata={'source': 'CV\\\\Michael_Chen_CV.md'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Chroma.from_documents(documents=screen_result, embedding=embeddings).as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "template = \"\"\"Summarize and highlight the experience, certificate or education in the CV which match with the JD as below:\n",
    "\n",
    "CV:\n",
    "{context}\n",
    "\n",
    "JD:\n",
    "{job_description}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = llm\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever , \"job_description\": lambda x: jd}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "res =chain.invoke(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the CVs provided, here are some highlights that match with the Job Description (JD):\n",
      "\n",
      "**CV 1: Emily Smith**\n",
      "\n",
      "* Education:\n",
      "\t+ Bachelor of Arts in Economics from University of British Columbia (2015-2019)\n",
      "\t\t- This degree is relevant to the JD's requirement for \"strong background in economics and statistics\".\n",
      "* Certifications:\n",
      "\t+ Certified Business Intelligence Professional (CBIP) - This certification is related to data visualization, analysis, and reporting, which are mentioned in the JD.\n",
      "* Skills:\n",
      "\t+ Data Visualization (Tableau, Power BI)\n",
      "\t+ Statistical Analysis\n",
      "\t+ Excel\n",
      "\n",
      "These skills align with the JD's requirements for designing, developing, and maintaining databases, creating data models, and implementing data administration policies.\n",
      "\n",
      "**CV 2: Michael Brown**\n",
      "\n",
      "* Education:\n",
      "\t+ Bachelor of Science in Software Engineering from Dalhousie University (2013-2017)\n",
      "\t\t- This degree is relevant to the JD's requirement for \"background in software engineering\".\n",
      "* Certifications:\n",
      "\t+ AWS Certified Data Analytics - Specialty - This certification is related to big data processing, which is mentioned in the JD.\n",
      "* Skills:\n",
      "\t+ Big Data (Hadoop, Spark)\n",
      "\t+ Cloud Platforms (AWS)\n",
      "\n",
      "These skills align with the JD's requirements for working with big data and cloud platforms.\n",
      "\n",
      "**CV 3: Michael Chen**\n",
      "\n",
      "* Education:\n",
      "\t+ Bachelor of Science in Software Engineering from Carleton University (2011-2015)\n",
      "\t\t- This degree is relevant to the JD's requirement for \"background in software engineering\".\n",
      "* Skills:\n",
      "\t+ Data Modeling\n",
      "\t+ ETL Development\n",
      "\n",
      "These skills align with the JD's requirements for designing data models and implementing data administration policies.\n",
      "\n",
      "Overall, these CVs highlight the candidates' education and certifications that match with the JD's requirements. Emily Smith's background in economics and statistics, Michael Brown's experience in big data processing, and Michael Chen's expertise in data modeling and ETL development are all relevant to the JD.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
